# Your Senses
An Assistive Technology Implementation With Apple's Swift CoreML 
# 

As the cases of visual, hearing, speech, and cognitive impairments double every decade, more people are left with inadequate support to complete mundane tasks. Your Senses seeks to provide for people with visual, hearing, speech, and cognitive impairments and break down barriers that restrict them from communicating or completing daily activities at ease.

#Image Classification using MobileNetV2
![alt text](https://github.com/pkallem/SwiftCoreML_AssistiveTechnology/blob/main/Screen%20Shot%202022-08-28%20at%2010.22.07%20PM.png?raw=true)

After the image is classified, the classifications along with confidence percentages are read out. This was designed with visually impaired people in mind. The user can make a gesture to scan a new object.
